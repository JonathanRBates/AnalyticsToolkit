{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnalyticsToolkit example for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jb2428\\\\Desktop\\\\python\\\\AnalyticsToolkit\\\\heart_disease'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\jb2428\\Desktop\\python\\AnalyticsToolkit\\analyticstoolkit')\n",
    "import analytic_toolkit as atk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read main data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "\n",
       "   slope   ca thal  OUTCOME  \n",
       "0    3.0  0.0  6.0        0  \n",
       "1    2.0  3.0  3.0        2  \n",
       "2    2.0  2.0  7.0        1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a single file in this analysis; \n",
    "# see aggregate_tables_ex.py for multiple files and more on data preprocessing\n",
    "df = pd.read_csv(r'data.csv')\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Mapping (u=continuous, b=binary, g=categorical)</th>\n",
       "      <th>Predictor</th>\n",
       "      <th>Description</th>\n",
       "      <th>Data Dictionary Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chest pain type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>resting blood pressure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chol</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fbs</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>restecg</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thalach</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exang</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slope</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ca</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OUTCOME</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diagnosis of heart disease (angiographic disea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Name      File Mapping (u=continuous, b=binary, g=categorical)  \\\n",
       "0            age  data.csv                                               u   \n",
       "1           sex   data.csv                                               b   \n",
       "2             cp  data.csv                                               g   \n",
       "3       trestbps  data.csv                                               u   \n",
       "4           chol  data.csv                                               u   \n",
       "5            fbs  data.csv                                               b   \n",
       "6        restecg  data.csv                                               g   \n",
       "7        thalach  data.csv                                               u   \n",
       "8          exang  data.csv                                               b   \n",
       "9        oldpeak  data.csv                                               u   \n",
       "10         slope  data.csv                                               g   \n",
       "11            ca  data.csv                                               u   \n",
       "12          thal  data.csv                                               g   \n",
       "13       OUTCOME  data.csv                                               b   \n",
       "\n",
       "    Predictor                                        Description  \\\n",
       "0         1.0                                                NaN   \n",
       "1         NaN                                                NaN   \n",
       "2         1.0                                   chest pain type    \n",
       "3         1.0                             resting blood pressure   \n",
       "4         1.0                                                NaN   \n",
       "5         NaN                                                NaN   \n",
       "6         NaN                                                NaN   \n",
       "7         1.0                                                NaN   \n",
       "8         1.0                                                NaN   \n",
       "9         1.0                                                NaN   \n",
       "10        1.0                                                NaN   \n",
       "11        NaN                                                NaN   \n",
       "12        NaN                                                NaN   \n",
       "13        NaN  diagnosis of heart disease (angiographic disea...   \n",
       "\n",
       "    Data Dictionary Document  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "5                        NaN  \n",
       "6                        NaN  \n",
       "7                        NaN  \n",
       "8                        NaN  \n",
       "9                        NaN  \n",
       "10                       NaN  \n",
       "11                       NaN  \n",
       "12                       NaN  \n",
       "13                       NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_codebook = r'codebook.xlsx'    \n",
    "pd.read_excel(f_codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### create reference standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "     \n",
    "## Get data transformation rules    \n",
    "include_cols, tr = atk.get_transformation_rules(f_codebook) \n",
    "X = df.loc[:,include_cols]\n",
    "y = df.loc[:,'OUTCOME'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   cp  trestbps   chol  thalach  exang  oldpeak  slope\n",
      "0  63.0  1.0     145.0  233.0    150.0    0.0      2.3    3.0\n",
      "1  67.0  4.0     160.0  286.0    108.0    1.0      1.5    2.0\n",
      "2  67.0  4.0     120.0  229.0    129.0    1.0      2.6    2.0\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "Name: OUTCOME, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(X.head(n=3))\n",
    "print(y.head(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### # # REMOVE FREQUENTLY MISSING\n",
    "# X.dropna(thresh=len(X) * 0.6, inplace=True, axis=1)  # filter out columns with more than 40% missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count:\n",
      " False    41\n",
      "True     34\n",
      "Name: OUTCOME, dtype: int64\n",
      "Test count:\n",
      " False    123\n",
      "True     105\n",
      "Name: OUTCOME, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split Data (Stratified splitting)\n",
    "train_size = 0.25 # proportion of training samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    train_size=train_size, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1)        \n",
    "\n",
    "project_reference_standard_file = 'project_train_test_split.data'\n",
    "pk.dump((X_train, X_test, y_train, y_test, tr), open(project_reference_standard_file, 'wb'))  \n",
    "\n",
    "## Data summary\n",
    "print('Train count:\\n', y_train.value_counts())\n",
    "print('Test count:\\n', y_test.value_counts())\n",
    "\n",
    "# generate_file_summary(X_train.reset_index(),'project_train_set.xlsx')   # see aggregate_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# XGBoost\n",
    "# DeepNets\n",
    "             \n",
    "metamodels = [\n",
    "             {'id': 'SGDClassifier',\n",
    "               'model': SGDClassifier,\n",
    "               'hyperparameters': {     \n",
    "                     'loss' : ['log'],\n",
    "                     'penalty' : ['elasticnet'],                                   \n",
    "                     'alpha' : [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "                     'l1_ratio' : [0.25, 0.5, 0.75],\n",
    "                     'class_weight': ['balanced']}\n",
    "                     },\n",
    "             {'id': 'Random Forest',\n",
    "               'model': RandomForestClassifier,\n",
    "               'hyperparameters': {  \n",
    "                     'n_estimators' : [10, 100],\n",
    "                     'criterion': ['gini', 'entropy'],\n",
    "                     'class_weight': [None, 'balanced'],\n",
    "                     'max_depth': [None, 5] }\n",
    "                     }     \n",
    "             ]               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGDClassifier --------------------\n",
      "Fold  0...............1...............2...............3...............4...............\n",
      "    auc_mean  auc_percentile_50   auc_std\n",
      "6   0.500000           0.500000  0.000000\n",
      "7   0.500000           0.500000  0.000000\n",
      "8   0.500000           0.500000  0.000000\n",
      "9   0.500000           0.500000  0.000000\n",
      "10  0.500000           0.500000  0.000000\n",
      "11  0.500000           0.500000  0.000000\n",
      "12  0.500000           0.500000  0.000000\n",
      "13  0.500000           0.500000  0.000000\n",
      "14  0.500000           0.500000  0.000000\n",
      "0   0.803968           0.803571  0.115362\n",
      "1   0.809722           0.839286  0.114899\n",
      "2   0.809921           0.821429  0.112017\n",
      "5   0.819643           0.821429  0.120374\n",
      "4   0.821825           0.821429  0.113567\n",
      "3   0.829365           0.821429  0.097501\n",
      "Best: {'alpha': 0.1, 'class_weight': 'balanced', 'loss': 'log', 'penalty': 'elasticnet', 'l1_ratio': 0.25}\n",
      "      auc_mean             0.829365\n",
      "auc_percentile_50    0.821429\n",
      "auc_std              0.097501\n",
      "Name: 3, dtype: float64\n",
      "Training Random Forest --------------------\n",
      "Fold  0................1................2................3................4................\n",
      "    auc_mean  auc_percentile_50   auc_std\n",
      "10  0.759524           0.738095  0.088436\n",
      "3   0.793849           0.746032  0.116319\n",
      "12  0.794048           0.767857  0.098303\n",
      "13  0.794444           0.767857  0.108621\n",
      "2   0.803175           0.777778  0.092454\n",
      "7   0.804762           0.785714  0.105369\n",
      "4   0.806349           0.794643  0.106241\n",
      "5   0.806349           0.785714  0.104882\n",
      "8   0.808333           0.794643  0.101829\n",
      "14  0.815476           0.803571  0.103783\n",
      "9   0.818452           0.839286  0.093093\n",
      "0   0.822024           0.776786  0.093765\n",
      "15  0.822619           0.803571  0.092933\n",
      "6   0.832937           0.821429  0.092779\n",
      "11  0.846825           0.821429  0.079508\n",
      "1   0.861310           0.833333  0.087757\n",
      "Best: {'class_weight': None, 'max_depth': None, 'n_estimators': 10, 'criterion': 'entropy'}\n",
      "      auc_mean             0.861310\n",
      "auc_percentile_50    0.833333\n",
      "auc_std              0.087757\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "atk.metamodels_cross_validate(X_train, \n",
    "                              y_train, \n",
    "                              transformation_rules=tr, \n",
    "                              metamodels=metamodels, \n",
    "                              kfolds=5, \n",
    "                              f_validate='metamodels_cross_validate_results.data',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SGDClassifier --------------------\n",
      "Hyperparameters:\n",
      "    alpha : 0.1\n",
      "    class_weight : balanced\n",
      "    loss : log\n",
      "    penalty : elasticnet\n",
      "    l1_ratio : 0.25\n",
      ">> AUC: 0.847\n",
      "Testing Random Forest --------------------\n",
      "Hyperparameters:\n",
      "    class_weight : None\n",
      "    max_depth : None\n",
      "    n_estimators : 10\n",
      "    criterion : entropy\n",
      ">> AUC: 0.807\n"
     ]
    }
   ],
   "source": [
    "atk.fit_optimal_model_to_training_data(X_train, \n",
    "                                       y_train, \n",
    "                                       X_test, \n",
    "                                       y_test, \n",
    "                                       f_validate='metamodels_cross_validate_results.data', \n",
    "                                       f_fit_models='fit_models.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write evaluation summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SGDClassifier --------------------\n",
      "Hyperparameters:\n",
      "    alpha : 0.1\n",
      "    class_weight : balanced\n",
      "    loss : log\n",
      "    penalty : elasticnet\n",
      "    l1_ratio : 0.25\n",
      ">> AUC: 0.847\n",
      "Testing Random Forest --------------------\n",
      "Hyperparameters:\n",
      "    class_weight : None\n",
      "    max_depth : None\n",
      "    n_estimators : 10\n",
      "    criterion : entropy\n",
      ">> AUC: 0.807\n"
     ]
    }
   ],
   "source": [
    "atk.summarize_test_results(X_test, \n",
    "                           y_test, \n",
    "                           f_validate='metamodels_cross_validate_results.data', \n",
    "                           f_fit_models='fit_models.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
