{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnalyticsToolkit: binary classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\jb2428\\Desktop\\python\\AnalyticsToolkit\\analyticstk')\n",
    "import analyticstk as atk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reference standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read main data set\n",
    "\n",
    "There is just one data file in this analysis; \n",
    "see aggregate_tables_ex.py for multiple files \n",
    "and more on data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "\n",
       "   slope   ca thal  OUTCOME  \n",
       "0    3.0  0.0  6.0        0  \n",
       "1    2.0  3.0  3.0        2  \n",
       "2    2.0  2.0  7.0        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_main = r'data.csv' \n",
    "df = pd.read_csv(f_main)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Mapping (u=continuous, b=binary, g=categorical)</th>\n",
       "      <th>Predictor</th>\n",
       "      <th>Description</th>\n",
       "      <th>Data Dictionary Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cp</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chest pain type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>resting blood pressure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chol</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fbs</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>restecg</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thalach</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exang</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slope</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ca</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thal</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OUTCOME</td>\n",
       "      <td>data.csv</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diagnosis of heart disease (angiographic disea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Name      File Mapping (u=continuous, b=binary, g=categorical)  \\\n",
       "0            age  data.csv                                               u   \n",
       "1           sex   data.csv                                               b   \n",
       "2             cp  data.csv                                               g   \n",
       "3       trestbps  data.csv                                               u   \n",
       "4           chol  data.csv                                               u   \n",
       "5            fbs  data.csv                                               b   \n",
       "6        restecg  data.csv                                               g   \n",
       "7        thalach  data.csv                                               u   \n",
       "8          exang  data.csv                                               b   \n",
       "9        oldpeak  data.csv                                               u   \n",
       "10         slope  data.csv                                               g   \n",
       "11            ca  data.csv                                               u   \n",
       "12          thal  data.csv                                               g   \n",
       "13       OUTCOME  data.csv                                               b   \n",
       "\n",
       "    Predictor                                        Description  \\\n",
       "0         1.0                                                NaN   \n",
       "1         NaN                                                NaN   \n",
       "2         1.0                                   chest pain type    \n",
       "3         1.0                             resting blood pressure   \n",
       "4         1.0                                                NaN   \n",
       "5         NaN                                                NaN   \n",
       "6         NaN                                                NaN   \n",
       "7         1.0                                                NaN   \n",
       "8         1.0                                                NaN   \n",
       "9         1.0                                                NaN   \n",
       "10        1.0                                                NaN   \n",
       "11        NaN                                                NaN   \n",
       "12        NaN                                                NaN   \n",
       "13        NaN  diagnosis of heart disease (angiographic disea...   \n",
       "\n",
       "    Data Dictionary Document  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "5                        NaN  \n",
       "6                        NaN  \n",
       "7                        NaN  \n",
       "8                        NaN  \n",
       "9                        NaN  \n",
       "10                       NaN  \n",
       "11                       NaN  \n",
       "12                       NaN  \n",
       "13                       NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_codebook = r'codebook.xlsx'    \n",
    "pd.read_excel(f_codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get transformation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include_cols, tr = atk.get_transformation_rules(f_codebook) \n",
    "X = df.loc[:,include_cols]\n",
    "y = df.loc[:,'OUTCOME'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   cp  trestbps   chol  thalach  exang  oldpeak  slope\n",
      "0  63.0  1.0     145.0  233.0    150.0    0.0      2.3    3.0\n",
      "1  67.0  4.0     160.0  286.0    108.0    1.0      1.5    2.0\n",
      "2  67.0  4.0     120.0  229.0    129.0    1.0      2.6    2.0\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "Name: OUTCOME, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(X.head(n=3))\n",
    "print(y.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE FREQUENTLY MISSING\n",
    "# X.dropna(thresh=len(X) * 0.6, inplace=True, axis=1)  # filter out columns with more than 40% missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "Use stratified splitting on outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_size = 0.25 # proportion of training samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    train_size=train_size, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write reference standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_reference_standard_file = 'atk_checkpoints//project_train_test_split.data'\n",
    "pk.dump((X_train, X_test, y_train, y_test, tr), open(project_reference_standard_file, 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate summary of reference standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count:\n",
      " False    41\n",
      "True     34\n",
      "Name: OUTCOME, dtype: int64\n",
      "Test count:\n",
      " False    123\n",
      "True     105\n",
      "Name: OUTCOME, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train count:\\n', y_train.value_counts())\n",
    "print('Test count:\\n', y_test.value_counts())\n",
    "# generate_file_summary(X_train.reset_index(),'project_train_set.xlsx')   # see aggregate_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# XGBoost\n",
    "# DeepNets\n",
    "             \n",
    "metamodels = [\n",
    "             {'id': 'SGDClassifier',\n",
    "               'model': SGDClassifier,\n",
    "               'hyperparameters': {     \n",
    "                     'loss' : ['log'],\n",
    "                     'penalty' : ['elasticnet'],                                   \n",
    "                     'alpha' : [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "                     'l1_ratio' : [0.25, 0.5, 0.75],\n",
    "                     'class_weight': ['balanced']}\n",
    "                     },\n",
    "             {'id': 'Random Forest',\n",
    "               'model': RandomForestClassifier,\n",
    "               'hyperparameters': {  \n",
    "                     'n_estimators' : [10, 100],\n",
    "                     'criterion': ['gini', 'entropy'],\n",
    "                     'class_weight': [None, 'balanced'],\n",
    "                     'max_depth': [None, 5] }\n",
    "                     }     \n",
    "             ]               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGDClassifier --------------------\n",
      "Fold  0...............1...............2...............3...............4...............\n",
      "    auc_mean  auc_percentile_50   auc_std\n",
      "6   0.500000           0.500000  0.000000\n",
      "7   0.500000           0.500000  0.000000\n",
      "8   0.500000           0.500000  0.000000\n",
      "9   0.500000           0.500000  0.000000\n",
      "10  0.500000           0.500000  0.000000\n",
      "11  0.500000           0.500000  0.000000\n",
      "12  0.500000           0.500000  0.000000\n",
      "13  0.500000           0.500000  0.000000\n",
      "14  0.500000           0.500000  0.000000\n",
      "1   0.784325           0.821429  0.131423\n",
      "0   0.802381           0.767857  0.111638\n",
      "2   0.809524           0.839286  0.110127\n",
      "5   0.828175           0.839286  0.121279\n",
      "4   0.832540           0.841270  0.113866\n",
      "3   0.832937           0.821429  0.096816\n",
      "Best: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.1, 'l1_ratio': 0.25, 'class_weight': 'balanced'}\n",
      "      auc_mean             0.832937\n",
      "auc_percentile_50    0.821429\n",
      "auc_std              0.096816\n",
      "Name: 3, dtype: float64\n",
      "Training Random Forest --------------------\n",
      "Fold  0................1................2................3................4................\n",
      "    auc_mean  auc_percentile_50   auc_std\n",
      "12  0.737897           0.698413  0.142701\n",
      "6   0.767659           0.722222  0.116901\n",
      "4   0.778075           0.776786  0.143651\n",
      "0   0.779365           0.723214  0.114411\n",
      "2   0.786409           0.767857  0.108820\n",
      "7   0.800099           0.769841  0.100425\n",
      "11  0.805159           0.793651  0.104512\n",
      "5   0.810714           0.776786  0.096395\n",
      "13  0.819048           0.785714  0.093253\n",
      "3   0.825397           0.803571  0.095494\n",
      "1   0.825794           0.812500  0.093559\n",
      "9   0.828373           0.803571  0.083187\n",
      "10  0.829563           0.785714  0.070296\n",
      "15  0.832143           0.785714  0.092857\n",
      "14  0.841468           0.821429  0.086081\n",
      "8   0.844048           0.857143  0.137106\n",
      "Best: {'max_depth': 5, 'criterion': 'gini', 'class_weight': None, 'n_estimators': 10}\n",
      "      auc_mean             0.844048\n",
      "auc_percentile_50    0.857143\n",
      "auc_std              0.137106\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "atk.metamodels_cross_validate(X_train, \n",
    "                              y_train, \n",
    "                              transformation_rules=tr, \n",
    "                              metamodels=metamodels, \n",
    "                              kfolds=5, \n",
    "                              f_validate='atk_checkpoints//metamodels_cross_validate_results.data',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SGDClassifier --------------------\n",
      "Hyperparameters:\n",
      "    penalty : elasticnet\n",
      "    loss : log\n",
      "    alpha : 0.1\n",
      "    l1_ratio : 0.25\n",
      "    class_weight : balanced\n",
      ">> AUC: 0.849\n",
      "Testing Random Forest --------------------\n",
      "Hyperparameters:\n",
      "    max_depth : 5\n",
      "    criterion : gini\n",
      "    class_weight : None\n",
      "    n_estimators : 10\n",
      ">> AUC: 0.825\n"
     ]
    }
   ],
   "source": [
    "atk.fit_optimal_model_to_training_data(X_train, \n",
    "                                       y_train, \n",
    "                                       X_test, \n",
    "                                       y_test, \n",
    "                                       f_validate='atk_checkpoints//metamodels_cross_validate_results.data', \n",
    "                                       f_fit_models='atk_checkpoints//fit_models.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write evaluation summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SGDClassifier --------------------\n",
      "Hyperparameters:\n",
      "    penalty : elasticnet\n",
      "    loss : log\n",
      "    alpha : 0.1\n",
      "    l1_ratio : 0.25\n",
      "    class_weight : balanced\n",
      ">> AUC: 0.849\n",
      "Testing Random Forest --------------------\n",
      "Hyperparameters:\n",
      "    max_depth : 5\n",
      "    criterion : gini\n",
      "    class_weight : None\n",
      "    n_estimators : 10\n",
      ">> AUC: 0.825\n"
     ]
    }
   ],
   "source": [
    "atk.summarize_test_results(X_test, \n",
    "                           y_test, \n",
    "                           f_validate='atk_checkpoints//metamodels_cross_validate_results.data', \n",
    "                           f_fit_models='atk_checkpoints//fit_models.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
